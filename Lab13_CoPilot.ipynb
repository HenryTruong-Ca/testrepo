{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Absolutely, let's roll up our sleeves and get into the data! We'll tackle each task step by step, crafting functions along the way to keep things organized and efficient. By the end, we'll have a solid script that not only processes your data but also provides valuable insights.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Import Libraries and Load Data**\n",
    "\n",
    "First things first, we'll import the necessary libraries and load the dataset.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_data(url):\n",
    "    \"\"\"\n",
    "    Loads the dataset from the given URL.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(url)\n",
    "    print(f\"Data loaded successfully. The dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "data_url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv'\n",
    "df = load_data(data_url)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Examine the Structure of the Data**\n",
    "\n",
    "Understanding the data's structure is crucial before diving into analysis.\n",
    "\n",
    "```python\n",
    "def examine_data(df):\n",
    "    \"\"\"\n",
    "    Displays column names, data types, and summary information.\n",
    "    \"\"\"\n",
    "    print(\"\\nDataFrame Columns and Data Types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    df.info()\n",
    "    \n",
    "    print(\"\\nFirst Five Rows of the DataFrame:\")\n",
    "    display(df.head())\n",
    "\n",
    "# Examine the data\n",
    "examine_data(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Handle Missing Data**\n",
    "\n",
    "Missing data can skew our analysis, so we'll need to handle it appropriately.\n",
    "\n",
    "```python\n",
    "def handle_missing_data(df):\n",
    "    \"\"\"\n",
    "    Identifies missing values and handles them by either imputing or dropping.\n",
    "    \"\"\"\n",
    "    # Identify missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(\"\\nColumns with Missing Values:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "    # For simplicity, we'll drop rows with missing values\n",
    "    df_cleaned = df.dropna()\n",
    "    print(f\"\\nAfter dropping missing values, the dataset contains {df_cleaned.shape[0]} rows.\")\n",
    "    return df_cleaned\n",
    "\n",
    "# Handle missing data\n",
    "df_clean = handle_missing_data(df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Analyze Key Columns**\n",
    "\n",
    "Let's explore key columns to understand the distribution of responses.\n",
    "\n",
    "```python\n",
    "def analyze_key_columns(df, columns):\n",
    "    \"\"\"\n",
    "    Calculates value counts for each specified column.\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        print(f\"\\nValue Counts for '{column}':\")\n",
    "        counts = df[column].value_counts()\n",
    "        print(counts)\n",
    "        \n",
    "        # Visualize the distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(data=df, y=column, order=counts.index)\n",
    "        plt.title(f\"Distribution of '{column}'\")\n",
    "        plt.xlabel('Count')\n",
    "        plt.ylabel(column)\n",
    "        plt.show()\n",
    "\n",
    "# Analyze specified columns\n",
    "key_columns = ['Employment', 'JobSat', 'YearsCodePro']\n",
    "analyze_key_columns(df_clean, key_columns)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 5: Visualize Job Satisfaction**\n",
    "\n",
    "Understanding job satisfaction levels can provide insights into industry trends.\n",
    "\n",
    "```python\n",
    "def visualize_job_satisfaction(df):\n",
    "    \"\"\"\n",
    "    Creates a pie chart to visualize the distribution of JobSat.\n",
    "    \"\"\"\n",
    "    job_sat_counts = df['JobSat'].value_counts()\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(job_sat_counts, labels=job_sat_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "    plt.title('Job Satisfaction Distribution')\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "    # Interpretation\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"The pie chart illustrates the proportion of respondents in each job satisfaction category, highlighting overall trends in the industry.\")\n",
    "\n",
    "# Visualize Job Satisfaction\n",
    "visualize_job_satisfaction(df_clean)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 6: Programming Languages Analysis**\n",
    "\n",
    "Comparing the languages professionals have worked with and those they want to work with can reveal shifts in technology preferences.\n",
    "\n",
    "```python\n",
    "def programming_languages_analysis(df):\n",
    "    \"\"\"\n",
    "    Compares the frequency of programming languages in 'LanguageHaveWorkedWith' and 'LanguageWantToWorkWith'.\n",
    "    Visualizes the overlap using a Venn diagram.\n",
    "    \"\"\"\n",
    "    from matplotlib_venn import venn2\n",
    "\n",
    "    # Process the data\n",
    "    have_worked_with = df['LanguageHaveWorkedWith'].dropna().str.split(';')\n",
    "    want_to_work_with = df['LanguageWantToWorkWith'].dropna().str.split(';')\n",
    "\n",
    "    # Flatten the lists and remove whitespace\n",
    "    have_worked_list = [lang.strip() for sublist in have_worked_with for lang in sublist]\n",
    "    want_to_work_list = [lang.strip() for sublist in want_to_work_with for lang in sublist]\n",
    "\n",
    "    # Create sets\n",
    "    set_have = set(have_worked_list)\n",
    "    set_want = set(want_to_work_list)\n",
    "\n",
    "    # Create the Venn diagram\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    venn2([set_have, set_want], set_labels=('Have Worked With', 'Want to Work With'))\n",
    "    plt.title('Programming Languages: Current vs Future Preferences')\n",
    "    plt.show()\n",
    "\n",
    "    # Interpretation\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"The Venn diagram shows the overlap between languages respondents know and those they aspire to learn, highlighting emerging trends.\")\n",
    "\n",
    "# Analyze programming languages\n",
    "programming_languages_analysis(df_clean)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 7: Analyze Remote Work Trends**\n",
    "\n",
    "Let's explore how remote work frequency varies by country.\n",
    "\n",
    "```python\n",
    "def analyze_remote_work_trends(df):\n",
    "    \"\"\"\n",
    "    Visualizes the distribution of 'RemoteWork' by 'Country'.\n",
    "    \"\"\"\n",
    "    # Focus on the top 10 countries by respondent count\n",
    "    top_countries = df['Country'].value_counts().head(10).index\n",
    "    df_top_countries = df[df['Country'].isin(top_countries)]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.countplot(data=df_top_countries, y='Country', hue='RemoteWork')\n",
    "    plt.title('Remote Work Frequency by Country')\n",
    "    plt.xlabel('Number of Respondents')\n",
    "    plt.ylabel('Country')\n",
    "    plt.legend(title='Remote Work Frequency', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Interpretation\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"The chart demonstrates the prevalence of remote work in different countries, offering insights into regional remote work adoption.\")\n",
    "\n",
    "# Analyze remote work trends\n",
    "analyze_remote_work_trends(df_clean)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 8: Correlation between Job Satisfaction and Experience**\n",
    "\n",
    "We'll examine if more experienced professionals are more satisfied with their jobs.\n",
    "\n",
    "```python\n",
    "def correlation_job_satisfaction_experience(df):\n",
    "    \"\"\"\n",
    "    Analyzes the correlation between 'JobSat' and 'YearsCodePro'.\n",
    "    \"\"\"\n",
    "    # Map 'JobSat' to numerical values\n",
    "    satisfaction_mapping = {\n",
    "        'Very satisfied': 5,\n",
    "        'Slightly satisfied': 4,\n",
    "        'Neither satisfied nor dissatisfied': 3,\n",
    "        'Slightly dissatisfied': 2,\n",
    "        'Very dissatisfied': 1\n",
    "    }\n",
    "    df['JobSatNum'] = df['JobSat'].map(satisfaction_mapping)\n",
    "\n",
    "    # Clean 'YearsCodePro'\n",
    "    df['YearsCodePro'] = df['YearsCodePro'].replace({'Less than 1 year': 0, 'More than 50 years': 51})\n",
    "    df['YearsCodePro'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n",
    "\n",
    "    # Drop missing values\n",
    "    df_corr = df.dropna(subset=['JobSatNum', 'YearsCodePro'])\n",
    "\n",
    "    # Calculate Spearman correlation\n",
    "    from scipy.stats import spearmanr\n",
    "    correlation, p_value = spearmanr(df_corr['JobSatNum'], df_corr['YearsCodePro'])\n",
    "    print(f\"\\nSpearman Correlation Coefficient: {correlation:.2f}\")\n",
    "\n",
    "    # Scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=df_corr, x='YearsCodePro', y='JobSatNum')\n",
    "    plt.title('Job Satisfaction vs. Professional Coding Experience')\n",
    "    plt.xlabel('Years of Professional Coding Experience')\n",
    "    plt.ylabel('Job Satisfaction (Numeric)')\n",
    "    plt.show()\n",
    "\n",
    "    # Interpretation\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"The scatter plot and correlation coefficient suggest whether there's a relationship between experience and job satisfaction.\")\n",
    "\n",
    "# Correlation analysis\n",
    "correlation_job_satisfaction_experience(df_clean)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 9: Cross-tabulation Analysis (Employment vs. Education Level)**\n",
    "\n",
    "Analyzing the relationship between employment status and education level can uncover important patterns.\n",
    "\n",
    "```python\n",
    "def cross_tabulation_analysis(df):\n",
    "    \"\"\"\n",
    "    Creates a cross-tabulation between 'Employment' and 'EdLevel'.\n",
    "    \"\"\"\n",
    "    crosstab = pd.crosstab(df['Employment'], df['EdLevel'], normalize='index')\n",
    "    crosstab.plot(kind='bar', stacked=True, figsize=(12, 8), colormap='Set2')\n",
    "    plt.title('Employment Status vs. Education Level')\n",
    "    plt.xlabel('Employment Status')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.legend(title='Education Level', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Interpretation\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"The stacked bar chart shows the distribution of education levels across different employment statuses.\")\n",
    "\n",
    "# Cross-tabulation\n",
    "cross_tabulation_analysis(df_clean)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 10: Export Cleaned Data**\n",
    "\n",
    "Saving the cleaned data for future use ensures we don't have to repeat the cleaning process.\n",
    "\n",
    "```python\n",
    "def export_cleaned_data(df, filename):\n",
    "    \"\"\"\n",
    "    Exports the cleaned DataFrame to a CSV file.\n",
    "    \"\"\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"\\nCleaned data exported to '{filename}'.\")\n",
    "\n",
    "# Export the data\n",
    "export_cleaned_data(df_clean, 'cleaned_survey_data.csv')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Thoughts**\n",
    "\n",
    "We've built a comprehensive script that handles data loading, cleaning, analysis, and visualization. By modularizing the tasks into functions, we can easily maintain and extend the code in the future.\n",
    "\n",
    "**Additional Ideas:**\n",
    "\n",
    "- **Deep Dive into Demographics:** Analyze how factors like age or country influence job satisfaction and technology preferences.\n",
    "- **Machine Learning Models:** Use the cleaned data to build predictive models for job satisfaction or salary.\n",
    "- **Interactive Dashboards:** Create interactive dashboards using Plotly or Dash for more dynamic data exploration.\n",
    "\n",
    "---\n",
    "\n",
    "Feel free to tweak these functions or add new ones to suit your specific needs. If there's a particular area you're curious about or if you have any questions, just let me know!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
