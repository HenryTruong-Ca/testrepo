{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Exploratory Data Analysis**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will work with a cleaned dataset to perform Exploratory Data Analysis or EDA. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Examine the structure of a dataset.\n",
    "\n",
    "- Handle missing values effectively.\n",
    "\n",
    "- Conduct summary statistics on key columns.\n",
    "\n",
    "- Analyze employment status, job satisfaction, programming language usage, and trends in remote work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Install and Import Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the necessary libraries for data manipulation and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_libraries():\n",
    "    \"\"\"\n",
    "    Imports necessary libraries for data manipulation and visualization.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    # Set visualization styles\n",
    "    sns.set(style='whitegrid')\n",
    "    plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "    print(\"Libraries imported successfully.\")\n",
    "    return pd, np, plt, sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<module 'pandas' from 'c:\\\\Users\\\\tdhoa\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\pandas\\\\__init__.py'>,\n",
       " <module 'numpy' from 'C:\\\\Users\\\\tdhoa\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\numpy\\\\__init__.py'>,\n",
       " <module 'matplotlib.pyplot' from 'C:\\\\Users\\\\tdhoa\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\matplotlib\\\\pyplot.py'>,\n",
       " <module 'seaborn' from 'c:\\\\Users\\\\tdhoa\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\seaborn\\\\__init__.py'>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_libraries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "This function imports the essential libraries:\n",
    "\n",
    "- pandas for data manipulation.\n",
    "\n",
    "- numpy for numerical operations.\n",
    "\n",
    "- matplotlib.pyplot and seaborn for data visualization.\n",
    "\n",
    "We also set some default styles for better-looking plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Load and Preview the Dataset\n",
    "Load the dataset from the provided URL. Use df.head() to display the first few rows to get an overview of the structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preview_dataset(url):\n",
    "    \"\"\"\n",
    "    Loads the dataset from the provided URL and displays the first few rows.\n",
    "    Parameters:\n",
    "    - url (str): The URL to load the dataset from.\n",
    "    Returns:\n",
    "    - df (DataFrame): The loaded DataFrame.\n",
    "    \"\"\"\n",
    "    pd, _, _, _ = import_libraries()\n",
    "    try:\n",
    "        df = pd.read_csv(url)\n",
    "        print(\"Dataset loaded successfully.\")\n",
    "        print(\"First five rows of the dataset:\")\n",
    "        print(df.head())\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while loading the dataset:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- The function loads data from a given URL.\n",
    "\n",
    "- It displays the first few rows to give you an overview.\n",
    "\n",
    "- Error handling is included to catch any issues during loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "First five rows of the dataset:\n",
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset_url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv'\n",
    "df = load_and_preview_dataset(dataset_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Handling Missing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify and manage missing values in critical columns such as `Employment`, `JobSat`, and `RemoteWork`. Implement a strategy to fill or drop these values, depending on the significance of the missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_data(df, critical_columns):\n",
    "    \"\"\"\n",
    "    Identifies and manages missing values in critical columns.\n",
    "    Parameters:\n",
    "    - df (DataFrame): The DataFrame to process.\n",
    "    - critical_columns (list): List of critical columns to check.\n",
    "    Returns:\n",
    "    - df (DataFrame): The DataFrame after handling missing data.\n",
    "    \"\"\"\n",
    "    pd, _, _, _ = import_libraries()\n",
    "    print(\"Handling missing data...\")\n",
    "\n",
    "    # Check initial shape\n",
    "    initial_shape = df.shape\n",
    "    print(f\"Initial dataset shape: {initial_shape}\")\n",
    "\n",
    "    # Drop rows with missing values in critical columns\n",
    "    df = df.dropna(subset=critical_columns)\n",
    "\n",
    "    # Check final shape\n",
    "    final_shape = df.shape\n",
    "    print(f\"Final dataset shape after dropping missing values: {final_shape}\")\n",
    "    print(f\"Total rows dropped: {initial_shape[0] - final_shape[0]}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- Drops rows where any of the critical columns have missing values.\n",
    "\n",
    "- Prints out the number of rows dropped for transparency.\n",
    "\n",
    "- This approach ensures that analyses on these columns are based on complete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n",
      "Handling missing data...\n",
      "Initial dataset shape: (65437, 114)\n",
      "Final dataset shape after dropping missing values: (29117, 114)\n",
      "Total rows dropped: 36320\n"
     ]
    }
   ],
   "source": [
    "critical_cols = ['Employment', 'JobSat', 'RemoteWork']\n",
    "df = handle_missing_data(df, critical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Analysis of Experience and Job Satisfaction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the relationship between years of professional coding experience (`YearsCodePro`) and job satisfaction (`JobSat`). Summarize `YearsCodePro` and calculate median satisfaction scores based on experience ranges.\n",
    "\n",
    "- Create experience ranges for `YearsCodePro` (e.g., `0-5`, `5-10`, `10-20`, `>20` years).\n",
    "\n",
    "- Calculate the median `JobSat` for each range.\n",
    "\n",
    "- Visualize the relationship using a bar plot or similar visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_experience_job_satisfaction(df):\n",
    "    \"\"\"\n",
    "    Analyzes the relationship between YearsCodePro and JobSat.\n",
    "    Returns:\n",
    "    - experience_median_job_sat (DataFrame): Median JobSat for each experience range.\n",
    "    \"\"\"\n",
    "    pd, np, plt, sns = import_libraries()\n",
    "    print(\"Analyzing experience and job satisfaction...\")\n",
    "\n",
    "    # Ensure 'YearsCodePro' is numeric\n",
    "    df = df.copy()\n",
    "    df['YearsCodePro'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n",
    "\n",
    "    # Define experience ranges\n",
    "    max_experience = df['YearsCodePro'].max()\n",
    "    bins = [0, 5, 10, 20, max_experience]\n",
    "    labels = ['0-5', '5-10', '10-20', '>20']\n",
    "    df['ExperienceRange'] = pd.cut(df['YearsCodePro'], bins=bins, labels=labels, right=False, include_lowest=True)\n",
    "\n",
    "    # Calculate median JobSat for each range\n",
    "    experience_median_job_sat = df.groupby('ExperienceRange', observed=False)['JobSat'].median().reset_index()\n",
    "\n",
    "    print(\"Median Job Satisfaction by Experience Range:\")\n",
    "    print(experience_median_job_sat)\n",
    "\n",
    "    # Visualize the relationship\n",
    "    #sns.barplot(x='ExperienceRange', y='JobSat', data=df, errorbar=None, estimator=np.median, palette='viridis')\n",
    "    sns.barplot(hue='ExperienceRange', y='JobSat', data=df, errorbar=None, estimator=np.median, palette='viridis', legend=False)\n",
    "    plt.title('Median Job Satisfaction by Experience Range')\n",
    "    plt.xlabel('Years of Professional Coding Experience')\n",
    "    plt.ylabel('Median Job Satisfaction')\n",
    "    plt.show()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- Converts YearsCodePro to numeric and handles non-numeric entries.\n",
    "\n",
    "- Categorizes experience into defined ranges.\n",
    "\n",
    "- Calculates and prints the median job satisfaction for each range.\n",
    "\n",
    "- Visualizes the results for better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_experience_job_satisfaction(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Visualize Job Satisfaction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a count plot to show the distribution of `JobSat` values. This provides insights into the overall satisfaction levels of respondents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_job_satisfaction(df):\n",
    "    \"\"\"\n",
    "    Creates a count plot to show the distribution of JobSat values.\n",
    "    \"\"\"\n",
    "    pd, np, plt, sns = import_libraries()\n",
    "    print(\"Visualizing job satisfaction...\")\n",
    "\n",
    "    # Plot the distribution\n",
    "    sns.countplot(x='JobSat', data=df, palette='coolwarm', order=sorted(df['JobSat'].unique()))\n",
    "    plt.title('Distribution of Job Satisfaction')\n",
    "    plt.xlabel('Job Satisfaction')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- Provides a visual representation of how job satisfaction is distributed among respondents.\n",
    "\n",
    "- Uses sorting to present the satisfaction levels in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a count plot to show the distribution of JobSat values.\n",
    "visualize_job_satisfaction(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Analyzing Remote Work Preferences by Job Role\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze trends in remote work based on job roles. Use the `RemoteWork` and `Employment` columns to explore preferences and examine if specific job roles prefer remote work more than others.\n",
    "\n",
    "- Use a count plot to show remote work distribution.\n",
    "\n",
    "- Cross-tabulate remote work preferences by employment type (e.g., full-time, part-time) and job roles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_remote_work_preferences(df):\n",
    "    \"\"\"\n",
    "    Analyzes trends in remote work based on job roles.\n",
    "    \"\"\"\n",
    "    pd, np, plt, sns = import_libraries()\n",
    "    print(\"Analyzing remote work preferences by job role...\")\n",
    "\n",
    "    # Plot remote work distribution\n",
    "    sns.countplot(x='RemoteWork', data=df, palette='Set2', order=sorted(df['RemoteWork'].unique()))\n",
    "    plt.title('Distribution of Remote Work Preferences')\n",
    "    plt.xlabel('Remote Work')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    # Cross-tabulate remote work by employment type\n",
    "    remote_employment_ct = pd.crosstab(df['Employment'], df['RemoteWork'])\n",
    "    print(\"Remote Work Preferences by Employment Type:\")\n",
    "    print(remote_employment_ct)\n",
    "\n",
    "    # Heatmap of the cross-tabulation\n",
    "    sns.heatmap(remote_employment_ct, annot=True, fmt='d', cmap='YlGnBu')\n",
    "    plt.title('Remote Work Preferences by Employment Type')\n",
    "    plt.ylabel('Employment Type')\n",
    "    plt.xlabel('Remote Work Preference')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- Visualizes how remote work preferences vary across the dataset.\n",
    "\n",
    "- Provides a heatmap to show the relationship between employment type and remote work preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_remote_work_preferences(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Analyzing Programming Language Trends by Region\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the popularity of programming languages by region. Use the `LanguageHaveWorkedWith` column to investigate which languages are most used in different regions.\n",
    "\n",
    "- Filter data by country or region.\n",
    "\n",
    "- Visualize the top programming languages by region with a bar plot or heatmap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_programming_language_trends(df, region_column='Country'):\n",
    "    \"\"\"\n",
    "    Analyzes the popularity of programming languages by region.\n",
    "    Parameters:\n",
    "    - df (DataFrame): The dataset to analyze.\n",
    "    - region_column (str): The column representing regions (e.g., 'Country').\n",
    "    \"\"\"\n",
    "    pd, np, plt, sns = import_libraries()\n",
    "    print(\"Analyzing programming language trends by region...\")\n",
    "\n",
    "    # Split the languages into lists\n",
    "    df['LanguagesWorkedWith'] = df['LanguageHaveWorkedWith'].str.split(';')\n",
    "\n",
    "    # Explode the languages\n",
    "    df_exploded = df.explode('LanguagesWorkedWith')\n",
    "\n",
    "    # Group and count\n",
    "    language_region_counts = df_exploded.groupby([region_column, 'LanguagesWorkedWith']).size().reset_index(name='Counts')\n",
    "\n",
    "    # For illustration, let's focus on the top 5 regions\n",
    "    top_regions = df[region_column].value_counts().head(5).index\n",
    "    filtered_data = language_region_counts[language_region_counts[region_column].isin(top_regions)]\n",
    "\n",
    "    # Pivot for heatmap\n",
    "    pivot_table = filtered_data.pivot(index='LanguagesWorkedWith', columns=region_column, values='Counts').fillna(0)\n",
    "\n",
    "    # Visualize with a heatmap\n",
    "    sns.heatmap(pivot_table, cmap='Blues')\n",
    "    plt.title('Programming Language Popularity by Region')\n",
    "    plt.ylabel('Programming Language')\n",
    "    plt.xlabel('Region')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- Handles multiple programming languages per respondent by splitting and exploding the data.\n",
    "\n",
    "- Focuses analysis on the top regions for clarity.\n",
    "\n",
    "- Uses a heatmap to show which languages are most popular in different regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_programming_language_trends(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Correlation Between Experience and Satisfaction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine how years of experience (`YearsCodePro`) correlate with job satisfaction (`JobSatPoints_1`). Use a scatter plot to visualize this relationship.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate_experience_satisfaction(df):\n",
    "    \"\"\"\n",
    "    Examines how YearsCodePro correlates with JobSatPoints_1.\n",
    "    \"\"\"\n",
    "    pd, np, plt, sns = import_libraries()\n",
    "    print(\"Analyzing correlation between experience and satisfaction...\")\n",
    "\n",
    "    # Ensure numeric types\n",
    "    df['YearsCodePro'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n",
    "    df['JobSatPoints_1'] = pd.to_numeric(df['JobSatPoints_1'], errors='coerce')\n",
    "\n",
    "    # Drop missing values\n",
    "    df_clean = df.dropna(subset=['YearsCodePro', 'JobSatPoints_1'])\n",
    "\n",
    "    # Scatter plot\n",
    "    sns.scatterplot(x='YearsCodePro', y='JobSatPoints_1', data=df_clean)\n",
    "    plt.title('Correlation Between Experience and Job Satisfaction')\n",
    "    plt.xlabel('Years of Professional Coding Experience')\n",
    "    plt.ylabel('Job Satisfaction Points')\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate correlation\n",
    "    correlation = df_clean['YearsCodePro'].corr(df_clean['JobSatPoints_1'])\n",
    "    print(f\"Pearson correlation coefficient: {correlation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- Converts relevant columns to numeric types.\n",
    "\n",
    "- Visualizes the relationship with a scatter plot.\n",
    "\n",
    "- Calculates and prints the Pearson correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlate_experience_satisfaction(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9: Educational Background and Employment Type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore how educational background (`EdLevel`) relates to employment type (`Employment`). Use cross-tabulation and visualizations to understand if higher education correlates with specific employment types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_education_employment(df):\n",
    "    \"\"\"\n",
    "    Explores how educational background relates to employment type.\n",
    "    \"\"\"\n",
    "    pd, np, plt, sns = import_libraries()\n",
    "    print(\"Analyzing educational background and employment type...\")\n",
    "\n",
    "    # Cross-tabulation\n",
    "    education_employment_ct = pd.crosstab(df['EdLevel'], df['Employment'])\n",
    "\n",
    "    print(\"Educational Background vs. Employment Type:\")\n",
    "    print(education_employment_ct)\n",
    "\n",
    "    # Visualize with a heatmap\n",
    "    sns.heatmap(education_employment_ct, annot=True, fmt='d', cmap='coolwarm')\n",
    "    plt.title('Education Level by Employment Type')\n",
    "    plt.ylabel('Education Level')\n",
    "    plt.xlabel('Employment Type')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- Uses cross-tabulation to examine the relationship.\n",
    "\n",
    "- Provides a heatmap for visual insight.\n",
    "\n",
    "- Helps understand if higher education levels correlate with certain employment types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_education_employment(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10: Save the Cleaned and Analyzed Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After your analysis, save the modified dataset for further use or sharing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cleaned_dataset(df, filename='cleaned_dataset.csv'):\n",
    "    \"\"\"\n",
    "    Saves the modified dataset to a CSV file.\n",
    "    Parameters:\n",
    "    - df (DataFrame): The DataFrame to save.\n",
    "    - filename (str): The name of the file to save to.\n",
    "    \"\"\"\n",
    "    pd, _, _, _ = import_libraries()\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Dataset saved successfully as {filename}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- Saves the DataFrame to a CSV file without the index.\n",
    "\n",
    "- Default filename is 'cleaned_dataset.csv', but you can specify any name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n",
      "Dataset saved successfully as cleaned_dataset.csv.\n"
     ]
    }
   ],
   "source": [
    "save_cleaned_dataset(df, 'cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Putting It All Together**\n",
    "\n",
    "Here's how you might use these functions in your script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "pd, np, plt, sns = import_libraries()\n",
    "\n",
    "# Step 2: Load and preview the dataset\n",
    "dataset_url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv'  # Replace with your actual dataset URL or file path\n",
    "df = load_and_preview_dataset(dataset_url)\n",
    "\n",
    "# Step 3: Handle missing data\n",
    "critical_columns = ['Employment', 'JobSat', 'RemoteWork']\n",
    "df = handle_missing_data(df, critical_columns)\n",
    "\n",
    "# Step 4: Analyze experience and job satisfaction\n",
    "analyze_experience_job_satisfaction(df)\n",
    "\n",
    "# Step 5: Visualize job satisfaction\n",
    "visualize_job_satisfaction(df)\n",
    "\n",
    "# Step 6: Analyze remote work preferences\n",
    "analyze_remote_work_preferences(df)\n",
    "\n",
    "# Step 7: Analyze programming language trends\n",
    "analyze_programming_language_trends(df)\n",
    "\n",
    "# Step 8: Correlation between experience and satisfaction\n",
    "correlate_experience_satisfaction(df)\n",
    "\n",
    "# Step 9: Analyze educational background and employment type\n",
    "analyze_education_employment(df)\n",
    "\n",
    "# Step 10: Save the cleaned and analyzed dataset\n",
    "save_cleaned_dataset(df, 'analyzed_dataset.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
